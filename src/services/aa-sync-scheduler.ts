import { prisma } from '@/lib/prisma';
import { cache } from '@/lib/redis';
import { ArtificialAnalysisScraperV2, AAModelData, initializeAAScraperV2 } from './aa-scraper-v2';
import { Prisma } from '@prisma/client';

interface SyncResult {
  success: boolean;
  modelsCount: number;
  errors: string[];
  timestamp: Date;
  duration: number;
}

export class AASyncScheduler {
  private scraper: ArtificialAnalysisScraperV2;
  private syncInterval: NodeJS.Timeout | null = null;
  private syncHistory: SyncResult[] = [];
  private isSyncing = false;
  private retryCount = 0;
  private maxRetries = 3;
  private baseInterval = 30 * 60 * 1000; // 30 minutes
  
  constructor() {
    this.scraper = initializeAAScraperV2();
  }

  /**
   * Start the sync scheduler
   */
  start(): void {
    console.log('üöÄ AA Sync Scheduler started');
    
    // Initial sync
    this.performSync();
    
    // Set up periodic sync
    this.scheduledSync();
  }

  /**
   * Stop the sync scheduler
   */
  stop(): void {
    if (this.syncInterval) {
      clearInterval(this.syncInterval);
      this.syncInterval = null;
      console.log('‚èπÔ∏è AA Sync Scheduler stopped');
    }
  }

  /**
   * Schedule periodic syncs with adaptive timing
   */
  private scheduledSync(): void {
    // Calculate interval based on time of day (peak vs off-peak)
    const interval = this.calculateSyncInterval();
    
    this.syncInterval = setInterval(() => {
      this.performSync();
    }, interval);
  }

  /**
   * Calculate sync interval based on time and load
   */
  private calculateSyncInterval(): number {
    const hour = new Date().getHours();
    
    // Peak hours (9 AM - 6 PM): More frequent syncs
    if (hour >= 9 && hour <= 18) {
      return this.baseInterval; // 30 minutes
    }
    
    // Off-peak hours: Less frequent syncs
    return this.baseInterval * 2; // 60 minutes
  }

  /**
   * Perform the actual sync operation
   */
  async performSync(): Promise<SyncResult> {
    if (this.isSyncing) {
      console.log('‚ö†Ô∏è Sync already in progress, skipping...');
      return {
        success: false,
        modelsCount: 0,
        errors: ['Sync already in progress'],
        timestamp: new Date(),
        duration: 0
      };
    }

    this.isSyncing = true;
    const startTime = Date.now();
    const errors: string[] = [];
    let modelsCount = 0;

    try {
      console.log('üîÑ Starting AA data sync...');
      
      // Scrape latest data from AA
      const models = await this.scraper.scrapeModels();
      
      if (!models || models.length === 0) {
        throw new Error('No models retrieved from AA scraper');
      }

      modelsCount = models.length;
      console.log(`üìä Retrieved ${modelsCount} models from Artificial Analysis`);

      // Save to database
      await this.saveModelsToDatabase(models);
      
      // Update cache
      await this.updateCache(models);
      
      // Calculate and save statistics
      await this.updateStatistics(models);
      
      // Reset retry count on success
      this.retryCount = 0;
      
      const duration = Date.now() - startTime;
      const result: SyncResult = {
        success: true,
        modelsCount,
        errors,
        timestamp: new Date(),
        duration
      };
      
      this.syncHistory.push(result);
      console.log(`‚úÖ Sync completed successfully in ${duration}ms`);
      
      return result;

    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';
      errors.push(errorMessage);
      console.error('‚ùå Sync failed:', errorMessage);
      
      // Implement exponential backoff for retries
      if (this.retryCount < this.maxRetries) {
        this.retryCount++;
        const retryDelay = Math.pow(2, this.retryCount) * 5000; // 5s, 10s, 20s
        console.log(`üîÑ Retrying sync in ${retryDelay / 1000} seconds...`);
        
        setTimeout(() => {
          this.performSync();
        }, retryDelay);
      }
      
      const duration = Date.now() - startTime;
      const result: SyncResult = {
        success: false,
        modelsCount: 0,
        errors,
        timestamp: new Date(),
        duration
      };
      
      this.syncHistory.push(result);
      return result;

    } finally {
      this.isSyncing = false;
    }
  }

  /**
   * Save models to database with chunk-based batch processing
   */
  private async saveModelsToDatabase(models: AAModelData[]): Promise<void> {
    console.log('üíæ Saving models to database using batch processing...');

    const CHUNK_SIZE = 25; // Process 25 models at a time
    const chunks = this.chunkArray(models, CHUNK_SIZE);

    console.log(`üì¶ Processing ${models.length} models in ${chunks.length} chunks of ${CHUNK_SIZE}`);

    // First, batch process providers to avoid duplicates
    await this.batchUpsertProviders(models);

    // Then process models in chunks
    let processedCount = 0;

    for (let i = 0; i < chunks.length; i++) {
      const chunk = chunks[i];
      console.log(`üîÑ Processing chunk ${i + 1}/${chunks.length} (${chunk.length} models)...`);

      try {
        await this.processBatchChunk(chunk, i + 1);
        processedCount += chunk.length;
        console.log(`‚úÖ Chunk ${i + 1} completed. Total processed: ${processedCount}/${models.length}`);

        // Small delay between chunks to prevent overwhelming the database
        if (i < chunks.length - 1) {
          await this.delay(100); // 100ms delay
        }

      } catch (error) {
        console.error(`‚ùå Error processing chunk ${i + 1}:`, error);
        // Continue with next chunk instead of failing completely
        continue;
      }
    }

    console.log(`‚úÖ Batch processing completed. Successfully processed ${processedCount}/${models.length} models`);
  }

  /**
   * Batch upsert providers to avoid race conditions
   */
  private async batchUpsertProviders(models: AAModelData[]): Promise<void> {
    console.log('üè¢ Batch upserting providers...');

    // Get unique providers
    const uniqueProviders = [...new Set(models.map(m => m.provider))];
    console.log(`üìä Found ${uniqueProviders.length} unique providers`);

    for (const providerName of uniqueProviders) {
      const slug = providerName.toLowerCase().replace(/[^a-z0-9]+/g, '-');

      try {
        await prisma.provider.upsert({
          where: { slug },
          update: {
            name: providerName,
            updatedAt: new Date()
          },
          create: {
            slug,
            name: providerName,
            regions: JSON.stringify(['global']),
            metadata: JSON.stringify({
              source: 'artificial-analysis',
              autoCreated: true
            })
          }
        });
      } catch (error) {
        console.warn(`‚ö†Ô∏è Warning: Could not upsert provider ${providerName}:`, error);
      }
    }

    console.log('‚úÖ Provider batch upsert completed');
  }

  /**
   * Process a single batch chunk with transaction safety
   */
  private async processBatchChunk(chunk: AAModelData[], chunkNumber: number): Promise<any[]> {
    // Use transaction for chunk consistency
    return await prisma.$transaction(async (tx) => {
      const results = [];

      for (const model of chunk) {
        try {
          // Get provider (should exist from batch upsert)
          const providerSlug = model.provider.toLowerCase().replace(/[^a-z0-9]+/g, '-');
          const provider = await tx.provider.findUnique({
            where: { slug: providerSlug }
          });

          if (!provider) {
            console.warn(`‚ö†Ô∏è Provider not found for model ${model.slug}: ${model.provider}`);
            continue;
          }

          // Upsert model with proper error handling
          const dbModel = await tx.model.upsert({
            where: { slug: model.slug },
            update: {
              name: model.name,
              providerId: provider.id,
              contextWindow: model.contextWindow || null,
              isActive: true,
              updatedAt: new Date(),
              // Update actual DB columns with AA data
              intelligenceScore: model.intelligenceScore ? Math.round(model.intelligenceScore) : null,
              outputSpeed: model.outputSpeed ? Math.round(model.outputSpeed) : null,
              inputPrice: model.price?.input ? new Prisma.Decimal(model.price.input) : null,
              outputPrice: model.price?.output ? new Prisma.Decimal(model.price.output) : null,
              lastVerified: new Date(),
              dataSource: 'api',
              metadata: JSON.stringify({
                aa: {
                  intelligenceScore: model.intelligenceScore,
                  outputSpeed: model.outputSpeed,
                  inputPrice: model.price?.input || 0,
                  outputPrice: model.price?.output || 0,
                  latency: model.latency,
                  rank: model.rank,
                  category: model.category,
                  trend: model.trend,
                  lastUpdated: model.lastUpdated
                },
                source: 'artificial-analysis',
                scrapedAt: new Date().toISOString(),
                scrapingMethod: 'batch-sync'
              })
            },
            create: {
              slug: model.slug,
              name: model.name,
              providerId: provider.id,
              description: `${model.name} by ${model.provider}`,
              contextWindow: model.contextWindow || null,
              maxOutputTokens: model.contextWindow ? Math.floor(model.contextWindow / 4) : null,
              modalities: JSON.stringify(['text']),
              capabilities: JSON.stringify(['chat', 'completion']),
              isActive: true,
              // Set actual DB columns with AA data for new models
              intelligenceScore: model.intelligenceScore ? Math.round(model.intelligenceScore) : null,
              outputSpeed: model.outputSpeed ? Math.round(model.outputSpeed) : null,
              inputPrice: model.price?.input ? new Prisma.Decimal(model.price.input) : null,
              outputPrice: model.price?.output ? new Prisma.Decimal(model.price.output) : null,
              lastVerified: new Date(),
              dataSource: 'api',
              metadata: JSON.stringify({
                aa: {
                  intelligenceScore: model.intelligenceScore,
                  outputSpeed: model.outputSpeed,
                  inputPrice: model.price?.input || 0,
                  outputPrice: model.price?.output || 0,
                  latency: model.latency,
                  rank: model.rank,
                  category: model.category,
                  trend: model.trend,
                  lastUpdated: model.lastUpdated
                },
                source: 'artificial-analysis',
                scrapedAt: new Date().toISOString(),
                scrapingMethod: 'batch-sync'
              })
            }
          });

          // Find existing status or create new one
          const existingStatus = await tx.modelStatus.findFirst({
            where: {
              modelId: dbModel.id,
              region: 'global'
            }
          });

          if (existingStatus) {
            // Update existing status
            await tx.modelStatus.update({
              where: { id: existingStatus.id },
              data: {
                status: model.intelligenceScore > 70 ? 'operational' : 'degraded',
                availability: this.calculateAvailability(model.intelligenceScore),
                latencyP50: Math.floor((model.latency || 0.5) * 1000), // Convert to ms
                latencyP95: Math.floor((model.latency || 0.5) * 1000 * 1.5),
                latencyP99: Math.floor((model.latency || 0.5) * 1000 * 2),
                errorRate: this.calculateErrorRate(model.intelligenceScore),
                checkedAt: new Date(),
                updatedAt: new Date()
              }
            });
          } else {
            // Create new status
            await tx.modelStatus.create({
              data: {
                modelId: dbModel.id,
                region: 'global',
                status: model.intelligenceScore > 70 ? 'operational' : 'degraded',
                availability: this.calculateAvailability(model.intelligenceScore),
                latencyP50: Math.floor((model.latency || 0.5) * 1000),
                latencyP95: Math.floor((model.latency || 0.5) * 1000 * 1.5),
                latencyP99: Math.floor((model.latency || 0.5) * 1000 * 2),
                errorRate: this.calculateErrorRate(model.intelligenceScore),
                requestsPerMin: 0,
                tokensPerMin: 0,
                usage: 0,
                checkedAt: new Date()
              }
            });
          }

          results.push({ model: model.slug, status: 'success' });

        } catch (modelError) {
          console.error(`‚ùå Failed to process model ${model.name}:`, modelError);
          results.push({ model: model.slug, status: 'failed', error: modelError });
          // Continue processing other models in the chunk
        }
      }

      console.log(`üìä Chunk ${chunkNumber}: ${results.filter(r => r.status === 'success').length}/${results.length} models processed successfully`);
      return results;
    }, {
      maxWait: 10000, // 10 seconds max wait
      timeout: 30000, // 30 seconds timeout
    });
  }

  /**
   * Utility method to chunk array into smaller arrays
   */
  private chunkArray<T>(array: T[], chunkSize: number): T[][] {
    const chunks = [];
    for (let i = 0; i < array.length; i += chunkSize) {
      chunks.push(array.slice(i, i + chunkSize));
    }
    return chunks;
  }

  /**
   * Utility method to add delay between operations
   */
  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  /**
   * Update Redis cache with latest data
   */
  private async updateCache(models: AAModelData[]): Promise<void> {
    console.log('üì¶ Updating Redis cache...');
    
    // Cache full model list
    await cache.set('aa:models:list', models, 300); // 5 minutes TTL
    
    // Cache individual models
    for (const model of models) {
      await cache.set(`aa:models:${model.slug}`, model, 600); // 10 minutes TTL
    }
    
    // Cache statistics
    const stats = this.calculateStats(models);
    await cache.set('aa:stats:global', stats, 60); // 1 minute TTL
    
    console.log('‚úÖ Cache updated');
  }

  /**
   * Calculate statistics from models
   */
  private calculateStats(models: AAModelData[]): any {
    const totalModels = models.length;
    const activeModels = models.filter(m => m.intelligenceScore > 60).length;
    const avgIntelligence = models.reduce((sum, m) => sum + m.intelligenceScore, 0) / totalModels;
    const avgSpeed = models.reduce((sum, m) => sum + m.outputSpeed, 0) / totalModels;
    const avgInputPrice = models.reduce((sum, m) => sum + m.price.input, 0) / totalModels;
    
    const providers = new Set(models.map(m => m.provider)).size;
    
    const categories = models.reduce((acc, m) => {
      acc[m.category] = (acc[m.category] || 0) + 1;
      return acc;
    }, {} as Record<string, number>);
    
    return {
      totalModels,
      activeModels,
      operationalModels: models.filter(m => m.intelligenceScore > 70).length,
      degradedModels: models.filter(m => m.intelligenceScore > 50 && m.intelligenceScore <= 70).length,
      outageModels: models.filter(m => m.intelligenceScore <= 50).length,
      avgAvailability: 95.0 + (avgIntelligence / 100) * 4.5, // 95-99.5% based on intelligence
      avgIntelligence: Math.round(avgIntelligence * 10) / 10,
      avgSpeed: Math.round(avgSpeed * 10) / 10,
      avgInputPrice: Math.round(avgInputPrice * 100) / 100,
      providers,
      categories,
      lastSync: new Date()
    };
  }

  /**
   * Update global statistics in database
   */
  private async updateStatistics(models: AAModelData[]): Promise<void> {
    const stats = this.calculateStats(models);
    
    // Save to a statistics table or as metadata
    await cache.set('aa:stats:latest', stats, 3600); // 1 hour TTL
    
    console.log('üìä Statistics updated:', {
      total: stats.totalModels,
      active: stats.activeModels,
      avgIntelligence: stats.avgIntelligence
    });
  }

  /**
   * Get sync history
   */
  getSyncHistory(): SyncResult[] {
    return this.syncHistory.slice(-10); // Last 10 syncs
  }

  /**
   * Get sync status
   */
  getSyncStatus(): {
    isSyncing: boolean;
    lastSync: Date | null;
    nextSync: Date | null;
    successRate: number;
  } {
    const lastSync = this.syncHistory.length > 0 
      ? this.syncHistory[this.syncHistory.length - 1].timestamp 
      : null;
    
    const nextSync = lastSync 
      ? new Date(lastSync.getTime() + this.calculateSyncInterval())
      : null;
    
    const successCount = this.syncHistory.filter(s => s.success).length;
    const successRate = this.syncHistory.length > 0 
      ? (successCount / this.syncHistory.length) * 100 
      : 0;
    
    return {
      isSyncing: this.isSyncing,
      lastSync,
      nextSync,
      successRate: Math.round(successRate * 10) / 10
    };
  }

  /**
   * Force manual sync
   */
  async forceSync(): Promise<SyncResult> {
    console.log('‚ö° Force sync requested');
    this.retryCount = 0; // Reset retry count for manual sync
    return this.performSync();
  }

  /**
   * Calculate availability based on intelligence score
   */
  private calculateAvailability(intelligenceScore: number): number {
    // Base availability on intelligence score with some realistic variance
    if (intelligenceScore > 80) {
      return Math.round((99.0 + (intelligenceScore - 80) / 100) * 10) / 10; // 99.0-99.2%
    } else if (intelligenceScore > 70) {
      return Math.round((98.0 + (intelligenceScore - 70) / 50) * 10) / 10; // 98.0-98.2%
    } else if (intelligenceScore > 60) {
      return Math.round((95.0 + (intelligenceScore - 60) / 33.3) * 10) / 10; // 95.0-95.3%
    } else {
      return Math.round((90.0 + intelligenceScore / 60 * 5) * 10) / 10; // 90.0-95.0%
    }
  }

  /**
   * Calculate error rate based on intelligence score
   */
  private calculateErrorRate(intelligenceScore: number): number {
    // Higher intelligence = lower error rate
    if (intelligenceScore > 80) {
      return Math.round((0.01 + (100 - intelligenceScore) / 1000) * 1000) / 1000; // 0.01-0.02%
    } else if (intelligenceScore > 70) {
      return Math.round((0.05 + (80 - intelligenceScore) / 200) * 1000) / 1000; // 0.05-0.10%
    } else if (intelligenceScore > 60) {
      return Math.round((0.2 + (70 - intelligenceScore) / 100) * 1000) / 1000; // 0.2-0.3%
    } else {
      return Math.round((0.5 + (60 - intelligenceScore) / 50) * 1000) / 1000; // 0.5-1.7%
    }
  }
}

// Singleton instance
let schedulerInstance: AASyncScheduler | null = null;

export function initializeAASyncScheduler(): AASyncScheduler {
  if (!schedulerInstance) {
    schedulerInstance = new AASyncScheduler();
  }
  return schedulerInstance;
}

export function getAASyncScheduler(): AASyncScheduler | null {
  return schedulerInstance;
}