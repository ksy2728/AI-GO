{
  "benchmarks": [
    {
      "id": "gpt-4-turbo-mmlu",
      "modelName": "GPT-4 Turbo",
      "provider": "OpenAI",
      "benchmarkName": "MMLU",
      "score": 86.4,
      "maxScore": 100,
      "percentile": 95,
      "date": "2024-11-01",
      "category": "reasoning",
      "description": "Massive Multitask Language Understanding - tests knowledge across 57 subjects"
    },
    {
      "id": "gpt-4o-mmlu",
      "modelName": "GPT-4o",
      "provider": "OpenAI",
      "benchmarkName": "MMLU",
      "score": 85.5,
      "maxScore": 100,
      "percentile": 93,
      "date": "2024-11-01",
      "category": "reasoning",
      "description": "Massive Multitask Language Understanding"
    },
    {
      "id": "claude-3-5-sonnet-mmlu",
      "modelName": "Claude 3.5 Sonnet",
      "provider": "Anthropic",
      "benchmarkName": "MMLU",
      "score": 88.3,
      "maxScore": 100,
      "percentile": 98,
      "date": "2024-10-01",
      "category": "reasoning",
      "description": "Massive Multitask Language Understanding"
    },
    {
      "id": "claude-3-opus-mmlu",
      "modelName": "Claude 3 Opus",
      "provider": "Anthropic",
      "benchmarkName": "MMLU",
      "score": 86.8,
      "maxScore": 100,
      "percentile": 96,
      "date": "2024-03-04",
      "category": "reasoning",
      "description": "Massive Multitask Language Understanding"
    },
    {
      "id": "gemini-1-5-pro-mmlu",
      "modelName": "Gemini 1.5 Pro",
      "provider": "Google",
      "benchmarkName": "MMLU",
      "score": 85.9,
      "maxScore": 100,
      "percentile": 94,
      "date": "2024-09-01",
      "category": "reasoning",
      "description": "Massive Multitask Language Understanding"
    },
    {
      "id": "gpt-4-turbo-humaneval",
      "modelName": "GPT-4 Turbo",
      "provider": "OpenAI",
      "benchmarkName": "HumanEval",
      "score": 87.0,
      "maxScore": 100,
      "percentile": 98,
      "date": "2024-11-01",
      "category": "coding",
      "description": "Python code generation benchmark"
    },
    {
      "id": "claude-3-5-sonnet-humaneval",
      "modelName": "Claude 3.5 Sonnet",
      "provider": "Anthropic",
      "benchmarkName": "HumanEval",
      "score": 92.0,
      "maxScore": 100,
      "percentile": 99,
      "date": "2024-10-01",
      "category": "coding",
      "description": "Python code generation benchmark"
    },
    {
      "id": "claude-3-opus-humaneval",
      "modelName": "Claude 3 Opus",
      "provider": "Anthropic",
      "benchmarkName": "HumanEval",
      "score": 84.9,
      "maxScore": 100,
      "percentile": 94,
      "date": "2024-03-04",
      "category": "coding",
      "description": "Python code generation benchmark"
    },
    {
      "id": "gemini-1-5-pro-humaneval",
      "modelName": "Gemini 1.5 Pro",
      "provider": "Google",
      "benchmarkName": "HumanEval",
      "score": 71.9,
      "maxScore": 100,
      "percentile": 85,
      "date": "2024-09-01",
      "category": "coding",
      "description": "Python code generation benchmark"
    },
    {
      "id": "gpt-4-turbo-gsm8k",
      "modelName": "GPT-4 Turbo",
      "provider": "OpenAI",
      "benchmarkName": "GSM8K",
      "score": 92.0,
      "maxScore": 100,
      "percentile": 97,
      "date": "2024-11-01",
      "category": "math",
      "description": "Grade school math word problems"
    },
    {
      "id": "claude-3-5-sonnet-gsm8k",
      "modelName": "Claude 3.5 Sonnet",
      "provider": "Anthropic",
      "benchmarkName": "GSM8K",
      "score": 96.4,
      "maxScore": 100,
      "percentile": 99,
      "date": "2024-10-01",
      "category": "math",
      "description": "Grade school math word problems"
    },
    {
      "id": "claude-3-opus-gsm8k",
      "modelName": "Claude 3 Opus",
      "provider": "Anthropic",
      "benchmarkName": "GSM8K",
      "score": 95.0,
      "maxScore": 100,
      "percentile": 99,
      "date": "2024-03-04",
      "category": "math",
      "description": "Grade school math word problems"
    },
    {
      "id": "gemini-1-5-pro-gsm8k",
      "modelName": "Gemini 1.5 Pro",
      "provider": "Google",
      "benchmarkName": "GSM8K",
      "score": 91.7,
      "maxScore": 100,
      "percentile": 96,
      "date": "2024-09-01",
      "category": "math",
      "description": "Grade school math word problems"
    },
    {
      "id": "gpt-4-turbo-hellaswag",
      "modelName": "GPT-4 Turbo",
      "provider": "OpenAI",
      "benchmarkName": "HellaSwag",
      "score": 95.3,
      "maxScore": 100,
      "percentile": 98,
      "date": "2024-11-01",
      "category": "reasoning",
      "description": "Commonsense reasoning about physical situations"
    },
    {
      "id": "claude-3-5-sonnet-hellaswag",
      "modelName": "Claude 3.5 Sonnet",
      "provider": "Anthropic",
      "benchmarkName": "HellaSwag",
      "score": 95.4,
      "maxScore": 100,
      "percentile": 99,
      "date": "2024-10-01",
      "category": "reasoning",
      "description": "Commonsense reasoning about physical situations"
    },
    {
      "id": "llama-3-1-405b-mmlu",
      "modelName": "Llama 3.1 405B",
      "provider": "Meta",
      "benchmarkName": "MMLU",
      "score": 85.2,
      "maxScore": 100,
      "percentile": 92,
      "date": "2024-07-23",
      "category": "reasoning",
      "description": "Massive Multitask Language Understanding"
    },
    {
      "id": "llama-3-1-405b-humaneval",
      "modelName": "Llama 3.1 405B",
      "provider": "Meta",
      "benchmarkName": "HumanEval",
      "score": 89.0,
      "maxScore": 100,
      "percentile": 98,
      "date": "2024-07-23",
      "category": "coding",
      "description": "Python code generation benchmark"
    },
    {
      "id": "llama-3-1-405b-gsm8k",
      "modelName": "Llama 3.1 405B",
      "provider": "Meta",
      "benchmarkName": "GSM8K",
      "score": 96.8,
      "maxScore": 100,
      "percentile": 99,
      "date": "2024-07-23",
      "category": "math",
      "description": "Grade school math word problems"
    },
    {
      "id": "mistral-large-mmlu",
      "modelName": "Mistral Large",
      "provider": "Mistral AI",
      "benchmarkName": "MMLU",
      "score": 81.2,
      "maxScore": 100,
      "percentile": 88,
      "date": "2024-02-26",
      "category": "reasoning",
      "description": "Massive Multitask Language Understanding"
    },
    {
      "id": "mistral-large-humaneval",
      "modelName": "Mistral Large",
      "provider": "Mistral AI",
      "benchmarkName": "HumanEval",
      "score": 45.0,
      "maxScore": 100,
      "percentile": 75,
      "date": "2024-02-26",
      "category": "coding",
      "description": "Python code generation benchmark"
    },
    {
      "id": "gpt-3-5-turbo-mmlu",
      "modelName": "GPT-3.5 Turbo",
      "provider": "OpenAI",
      "benchmarkName": "MMLU",
      "score": 70.0,
      "maxScore": 100,
      "percentile": 70,
      "date": "2024-11-01",
      "category": "reasoning",
      "description": "Massive Multitask Language Understanding"
    },
    {
      "id": "gpt-3-5-turbo-humaneval",
      "modelName": "GPT-3.5 Turbo",
      "provider": "OpenAI",
      "benchmarkName": "HumanEval",
      "score": 48.1,
      "maxScore": 100,
      "percentile": 78,
      "date": "2024-11-01",
      "category": "coding",
      "description": "Python code generation benchmark"
    },
    {
      "id": "gpt-3-5-turbo-gsm8k",
      "modelName": "GPT-3.5 Turbo",
      "provider": "OpenAI",
      "benchmarkName": "GSM8K",
      "score": 57.1,
      "maxScore": 100,
      "percentile": 60,
      "date": "2024-11-01",
      "category": "math",
      "description": "Grade school math word problems"
    },
    {
      "id": "claude-3-haiku-mmlu",
      "modelName": "Claude 3 Haiku",
      "provider": "Anthropic",
      "benchmarkName": "MMLU",
      "score": 75.2,
      "maxScore": 100,
      "percentile": 78,
      "date": "2024-03-04",
      "category": "reasoning",
      "description": "Massive Multitask Language Understanding"
    },
    {
      "id": "claude-3-haiku-humaneval",
      "modelName": "Claude 3 Haiku",
      "provider": "Anthropic",
      "benchmarkName": "HumanEval",
      "score": 75.9,
      "maxScore": 100,
      "percentile": 88,
      "date": "2024-03-04",
      "category": "coding",
      "description": "Python code generation benchmark"
    },
    {
      "id": "claude-3-haiku-gsm8k",
      "modelName": "Claude 3 Haiku",
      "provider": "Anthropic",
      "benchmarkName": "GSM8K",
      "score": 88.9,
      "maxScore": 100,
      "percentile": 94,
      "date": "2024-03-04",
      "category": "math",
      "description": "Grade school math word problems"
    },
    {
      "id": "gemini-1-5-flash-mmlu",
      "modelName": "Gemini 1.5 Flash",
      "provider": "Google",
      "benchmarkName": "MMLU",
      "score": 78.9,
      "maxScore": 100,
      "percentile": 82,
      "date": "2024-09-01",
      "category": "reasoning",
      "description": "Massive Multitask Language Understanding"
    },
    {
      "id": "gemini-1-5-flash-humaneval",
      "modelName": "Gemini 1.5 Flash",
      "provider": "Google",
      "benchmarkName": "HumanEval",
      "score": 74.3,
      "maxScore": 100,
      "percentile": 87,
      "date": "2024-09-01",
      "category": "coding",
      "description": "Python code generation benchmark"
    },
    {
      "id": "gemini-1-5-flash-gsm8k",
      "modelName": "Gemini 1.5 Flash",
      "provider": "Google",
      "benchmarkName": "GSM8K",
      "score": 86.2,
      "maxScore": 100,
      "percentile": 91,
      "date": "2024-09-01",
      "category": "math",
      "description": "Grade school math word problems"
    },
    {
      "id": "llama-3-1-70b-mmlu",
      "modelName": "Llama 3.1 70B",
      "provider": "Meta",
      "benchmarkName": "MMLU",
      "score": 79.3,
      "maxScore": 100,
      "percentile": 83,
      "date": "2024-07-23",
      "category": "reasoning",
      "description": "Massive Multitask Language Understanding"
    },
    {
      "id": "llama-3-1-70b-humaneval",
      "modelName": "Llama 3.1 70B",
      "provider": "Meta",
      "benchmarkName": "HumanEval",
      "score": 80.5,
      "maxScore": 100,
      "percentile": 91,
      "date": "2024-07-23",
      "category": "coding",
      "description": "Python code generation benchmark"
    },
    {
      "id": "llama-3-1-70b-gsm8k",
      "modelName": "Llama 3.1 70B",
      "provider": "Meta",
      "benchmarkName": "GSM8K",
      "score": 95.1,
      "maxScore": 100,
      "percentile": 98,
      "date": "2024-07-23",
      "category": "math",
      "description": "Grade school math word problems"
    }
  ],
  "benchmarkSuites": [
    {
      "name": "MMLU",
      "description": "Massive Multitask Language Understanding - tests knowledge across 57 subjects including STEM, humanities, social sciences, and more",
      "category": "reasoning",
      "maxScore": 100,
      "unit": "%"
    },
    {
      "name": "HumanEval",
      "description": "Python code generation benchmark testing the ability to generate functionally correct code from docstrings",
      "category": "coding",
      "maxScore": 100,
      "unit": "%"
    },
    {
      "name": "GSM8K",
      "description": "Grade school math word problems requiring multi-step reasoning",
      "category": "math",
      "maxScore": 100,
      "unit": "%"
    },
    {
      "name": "HellaSwag",
      "description": "Commonsense reasoning about physical situations",
      "category": "reasoning",
      "maxScore": 100,
      "unit": "%"
    }
  ],
  "lastUpdated": "2024-11-01T12:00:00Z",
  "version": "1.0"
}