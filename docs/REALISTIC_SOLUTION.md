# 현실적인 TempDataService 개선 방안

## 🎯 수정된 문제 정의

### 현재 상황 재분석
- **로컬**: API 키 있는 15개 모델만 실제 사용 가능
- **배포**: 동일한 15개 모델의 목업 데이터
- **36개 모델**: DB에는 있지만 API 키 없어서 의미 없음

## ✅ 올바른 해결 방안

### 1. 현재 TempDataService는 올바름
- 15개 모델 = 실제 사용 가능한 모델들
- API 키가 있는 서비스들만 포함
- 36개로 확장하는 것은 불필요함

### 2. 개선할 부분들

#### A. 데이터 품질 개선
```typescript
// 현재 TempDataService의 문제점들
1. 일부 모델 정보가 오래됨 (2023년 데이터)
2. 가격 정보가 실제와 다를 수 있음
3. 벤치마크 스코어가 임의로 설정됨
```

#### B. 실제 데이터와 동기화
- **OpenAI**: GPT-4o, GPT-4o mini, GPT-3.5 Turbo 최신 정보
- **Anthropic**: Claude 3.5 Sonnet, Claude 3 Haiku 최신 정보
- **Google**: Gemini Pro, Gemini 1.5 Pro 최신 정보
- **Meta**: Llama 3.1 시리즈 최신 정보

#### C. 로컬-배포 일관성
- 로컬에서 실제로 작동하는 모델들만 배포에도 포함
- 동일한 15개 모델 정보 동기화

## 🔧 즉시 수행할 작업

### 1. 현재 TempDataService 검토
- 15개 모델 정보 최신화
- 2024년 기준 가격/성능 정보 업데이트
- 실제 벤치마크 점수로 교체

### 2. API 키 확인
- `.env`에서 실제 사용 가능한 API 키 확인
- 해당 모델들만 TempDataService에 유지

### 3. 데이터 검증
- 로컬에서 실제 API 호출 테스트
- 작동하는 모델들의 정확한 정보 수집

## 💡 장기 계획

### Phase 1: 데이터 품질 개선 (즉시)
- [ ] 현재 15개 모델 정보 검증
- [ ] 최신 가격/성능 데이터 업데이트
- [ ] 실제 벤치마크 스코어 적용

### Phase 2: API 키 기반 동적 필터링 (1주)
- [ ] 환경변수에서 API 키 존재 여부 확인
- [ ] API 키 있는 모델만 동적으로 표시
- [ ] 새 API 키 추가 시 자동으로 모델 추가

### Phase 3: 실시간 동기화 (1개월)
- [ ] 실제 API 상태와 TempData 동기화
- [ ] 주기적 데이터 업데이트 시스템
- [ ] 모델 추가/제거 자동화

## 🚨 피해야 할 것들

❌ **36개 모델로 확장하지 마세요**
- API 키 없는 모델은 의미 없음
- 사용자에게 혼란만 가중
- 유지보수 부담 증가

❌ **가짜 데이터 추가하지 마세요**  
- 실제로 작동하지 않는 모델 표시
- 사용자 기대치와 현실의 괴리
- 서비스 신뢰도 저하

## ✅ 권장 사항

### 현재 상황에서 최선의 선택
1. **15개 모델 유지**: API 키 있는 모델들만
2. **데이터 품질 개선**: 정확하고 최신 정보로 업데이트  
3. **일관성 확보**: 로컬-배포 버전 완전 동기화

### 즉시 실행 계획
1. **현재 API 키 확인**
2. **실제 작동하는 모델 테스트**
3. **TempDataService 데이터 검증 및 업데이트**
4. **배포 후 테스트**

---

**결론**: 36개로 확장하지 말고, 현재 15개 모델의 품질을 개선하는 것이 올바른 방향입니다.