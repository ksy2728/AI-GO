name: AA Data Scraper

on:
  schedule:
    # Run 4 times a day: 6AM, 12PM, 6PM, 12AM KST (UTC+9)
    - cron: '0 21,3,9,15 * * *'  # UTC times
  workflow_dispatch:  # Allow manual trigger
    inputs:
      debug_mode:
        description: 'Enable debug mode'
        required: false
        default: 'false'
        type: boolean

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    permissions:
      contents: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.PAT || secrets.GITHUB_TOKEN }}
          persist-credentials: true
          fetch-depth: 0
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
      
      - name: Install dependencies
        run: |
          # Install all dependencies including devDependencies for playwright
          npm ci || npm install
          # Ensure playwright browsers are installed
          npx playwright install chromium --with-deps
      
      - name: Create data directory
        run: mkdir -p public/data
      
      - name: Run AA scraper
        env:
          DEBUG_MODE: ${{ github.event.inputs.debug_mode }}
        run: |
          # Check if script exists
          ls -la scripts/
          # Run the scraper
          node scripts/aa-scraper-standalone.js || echo "Scraper failed with exit code $?"
        timeout-minutes: 5
        
      - name: Validate scraped data
        run: node scripts/validate-aa-data.js
        
      - name: Commit and push changes
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

          # Copy to src/data for Vercel build
          mkdir -p src/data
          cp public/data/aa-models.json src/data/aa-models.json

          # Add both data files
          git add public/data/aa-models.json src/data/aa-models.json
          
          # Check if there are changes
          if git diff --cached --quiet; then
            echo "No changes to commit"
          else
            # Get model count from JSON
            MODEL_COUNT=$(cat public/data/aa-models.json | grep -o '"name"' | wc -l)
            
            # Commit with detailed message
            git commit -m "ðŸ¤– Update AA models data [skip ci]" \
                       -m "" \
                       -m "- Updated: $(date -u +'%Y-%m-%d %H:%M:%S UTC')" \
                       -m "- Models scraped: $MODEL_COUNT" \
                       -m "- Source: Artificial Analysis (artificialanalysis.ai)"
            
            # Push changes
            git push
          fi
      
      - name: Upload debug artifacts (on failure)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: debug-screenshots
          path: |
            screenshots/
            public/data/
          retention-days: 7
      
      - name: Notify success (optional)
        if: success() && github.event_name == 'workflow_dispatch'
        run: |
          echo "âœ… AA scraping completed successfully!"
          echo "Models updated at: $(date -u +'%Y-%m-%d %H:%M:%S UTC')"