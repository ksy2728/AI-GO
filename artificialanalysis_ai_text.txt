Follow us on Twitter or LinkedIn to stay up to date with future analysis
Artificial Analysis
Models
Speech, Image, Video
Hardware
Leaderboards
AI Trends
MicroEvals
Arenas
Articles
About
Search...
‚åòK
Insights Login
Independent analysis of AI

Understand the AI landscape to choose the best model and provider for your use case

State of Generative Media 2025 Survey

Supported by  fal
Participate in the Survey

State of AI (Highlights) - Q2 2025

Analysis of the AI landscape and the key trends shaping AI
Access Report

Highlights

INTELLIGENCE
Artificial Analysis Intelligence Index; Higher is better
GPT-5 (high)
GPT-5(medium)
Grok 4
Grok 4 Fast
Gemini 2.5Pro
Claude 4.1Opus
gpt-oss-120B(high)
Qwen3 235B2507
Claude 4Sonnet
DeepSeek V3.1
Gemini 2.5Flash
GPT-4.1
Llama 4 Maverick
67
66
65
60
60
59
58
57
57
54
51
43
36
SPEED
Output Tokens per Second; Higher is better
Grok 4 Fast
gpt-oss-120B(high)
Gemini 2.5Flash
GPT-5(medium)
GPT-5 (high)
Gemini 2.5Pro
Llama 4 Maverick
GPT-4.1
Qwen3 235B2507
Claude 4Sonnet
Grok 4
Claude 4.1Opus
DeepSeek V3.1
256
254
252
223
171
154
140
95
67
56
45
42
PRICE
USD per 1M Tokens; Lower is better
gpt-oss-120B(high)
Grok 4 Fast
Llama 4 Maverick
Gemini 2.5Flash
DeepSeek V3.1
Qwen3 235B2507
GPT-5(medium)
GPT-5 (high)
Gemini 2.5Pro
GPT-4.1
Claude 4Sonnet
Grok 4
Claude 4.1Opus
0.3
0.3
0.4
0.8
1
2.6
3.4
3.4
3.4
3.5
6
6
30

How do the latest LLMs stack up?

Compare Language Models

How do the latest OpenAI models compare?

OpenAI Models Compared

Where can you get an API for DeepSeek R1?

DeepSeek R1 Providers

Who has the best Video Generation model?

Video Arena

Which model is fastest with 100k token prompts?

Long Context Latency
Intelligence

Intelligence of leading AI models based on our independent evaluations

Artificial Analysis Intelligence Index
Reasoning vs Non-Reasoning
Open Weights vs Proprietary
Coding Index
Artificial Analysis Intelligence Index
Artificial Analysis Intelligence Index v3.0 incorporates 10 evaluations: MMLU-Pro, GPQA Diamond, Humanity's Last Exam, LiveCodeBench, SciCode, AIME 2025, IFBench, AA-LCR, Terminal-Bench Hard, ùúè¬≤-Bench Telecom
Artificial Analysis
GPT-5(high)
Grok 4
Grok 4Fast
Gemini 2.5Pro
Claude 4.1Opus
gpt-oss-120B(high)
Qwen3 235B2507
Claude 4Sonnet
DeepSeekV3.1
DeepSeekR1 0528
Gemini 2.5Flash
Kimi K2 0905
GLM-4.5
Grok CodeFast 1
LlamaNemotronSuper 49B v1.5
gpt-oss-20B(high)
DeepSeek V3.1
GPT-5 (minimal)
GPT-4.1
EXAONE 4.032B
Solar Pro2
Llama 4Maverick
Mistral Medium3.1
67
65
60
60
59
58
57
57
54
52
51
50
49
49
45
45
45
43
43
43
38
36
35
23 of 275 models selected
+ Add model from specific provider
Artificial Analysis Intelligence Index: Combination metric covering multiple dimensions of intelligence - the simplest way to compare how smart models are. Version 3.0 was released in September 2025 and includes: MMLU-Pro, GPQA Diamond, Humanity's Last Exam, LiveCodeBench, SciCode, AIME 2025, IFBench, AA-LCR, Terminal-Bench Hard, ùúè¬≤-Bench Telecom. See Intelligence Index methodology for further details, including a breakdown of each evaluation and how we run them.
Frontier Language Model Intelligence, Over Time
Artificial Analysis Intelligence Index v3.0 incorporates 10 evaluations: MMLU-Pro, GPQA Diamond, Humanity's Last Exam, LiveCodeBench, SciCode, AIME 2025, IFBench, AA-LCR, Terminal-Bench Hard, ùúè¬≤-Bench Telecom
Alibaba
Anthropic
DeepSeek
Google
LG AI Research
Meta
Mistral
Moonshot AI
OpenAI
Upstage
xAI
Z AI
Nov ‚Äô22
Jan ‚Äô23
Mar ‚Äô23
May ‚Äô23
Jul ‚Äô23
Sep ‚Äô23
Nov ‚Äô23
Jan ‚Äô24
Mar ‚Äô24
May ‚Äô24
Jul ‚Äô24
Sep ‚Äô24
Nov ‚Äô24
Jan ‚Äô25
Mar ‚Äô25
May ‚Äô25
Jul ‚Äô25
Sep ‚Äô25
Nov ‚Äô25
Release Date
0
10
20
30
40
50
60
70
Artificial Analysis Intelligence Index
Artificial Analysis
12 of 28 items selected
Artificial Analysis Intelligence Index: Combination metric covering multiple dimensions of intelligence - the simplest way to compare how smart models are. Version 3.0 was released in September 2025 and includes: MMLU-Pro, GPQA Diamond, Humanity's Last Exam, LiveCodeBench, SciCode, AIME 2025, IFBench, AA-LCR, Terminal-Bench Hard, ùúè¬≤-Bench Telecom. See Intelligence Index methodology for further details, including a breakdown of each evaluation and how we run them.
Intelligence Evaluations
Intelligence evaluations measured independently by Artificial Analysis; Higher is better
Results claimed by AI Lab (not yet independently verified)
MMLU-Pro (Reasoning & Knowledge)
Claude 4.1Opus
GPT-5(high)
Grok 4
Gemini 2.5Pro
DeepSeekV3.1
Grok 4Fast
DeepSeekR1 0528
Qwen3 235B2507
Claude 4Sonnet
GLM-4.5
DeepSeek V3.1
Gemini 2.5Flash
Kimi K2 0905
EXAONE 4.032B
LlamaNemotronSuper 49B v1.5
Llama 4Maverick
gpt-oss-120B(high)
GPT-5 (minimal)
GPT-4.1
Solar Pro2
Grok CodeFast 1
gpt-oss-20B(high)
Mistral Medium3.1
88%
87%
87%
86%
85%
85%
85%
84%
84%
84%
83%
83%
82%
82%
81%
81%
81%
81%
81%
81%
79%
74%
68%
GPQA Diamond (Scientific Reasoning)
Grok 4
GPT-5(high)
Grok 4Fast
Gemini 2.5Pro
DeepSeekR1 0528
Claude 4.1Opus
Gemini 2.5Flash
Qwen3 235B2507
gpt-oss-120B(high)
GLM-4.5
DeepSeekV3.1
Claude 4Sonnet
Kimi K2 0905
LlamaNemotronSuper 49B v1.5
EXAONE 4.032B
DeepSeek V3.1
Grok CodeFast 1
Solar Pro2
GPT-5 (minimal)
Llama 4Maverick
GPT-4.1
gpt-oss-20B(high)
Mistral Medium3.1
88%
85%
85%
84%
81%
81%
79%
79%
78%
78%
78%
78%
77%
75%
74%
74%
73%
69%
67%
67%
67%
62%
59%
Humanity's Last Exam (Reasoning & Knowledge)
GPT-5(high)
Grok 4
Gemini 2.5Pro
gpt-oss-120B(high)
Grok 4Fast
Qwen3 235B2507
DeepSeekR1 0528
DeepSeekV3.1
GLM-4.5
Claude 4.1Opus
Gemini 2.5Flash
EXAONE 4.032B
Claude 4Sonnet
gpt-oss-20B(high)
Grok CodeFast 1
Solar Pro2
LlamaNemotronSuper 49B v1.5
DeepSeek V3.1
Kimi K2 0905
GPT-5 (minimal)
Llama 4Maverick
GPT-4.1
Mistral Medium3.1
26.5%
23.9%
21.1%
18.5%
17.0%
15.0%
14.9%
13.0%
12.2%
11.9%
11.1%
10.5%
9.6%
8.5%
7.5%
7.0%
6.8%
6.3%
6.3%
5.4%
4.8%
4.6%
4.4%
LiveCodeBench (Coding)
Grok 4Fast
Grok 4
Gemini 2.5Pro
Qwen3 235B2507
DeepSeekV3.1
DeepSeekR1 0528
EXAONE 4.032B
GLM-4.5
LlamaNemotronSuper 49B v1.5
gpt-oss-20B(high)
Gemini 2.5Flash
GPT-5(high)
Grok CodeFast 1
Claude 4Sonnet
Claude 4.1Opus
gpt-oss-120B(high)
Solar Pro2
Kimi K2 0905
DeepSeek V3.1
GPT-5 (minimal)
GPT-4.1
Mistral Medium3.1
Llama 4Maverick
83%
82%
80%
79%
78%
77%
75%
74%
74%
72%
70%
67%
66%
66%
65%
64%
62%
61%
58%
56%
46%
41%
40%
SciCode (Coding)
Grok 4
Grok 4Fast
GPT-5(high)
Gemini 2.5Pro
Qwen3 235B2507
Claude 4.1Opus
DeepSeekR1 0528
Claude 4Sonnet
Gemini 2.5Flash
DeepSeekV3.1
GPT-5 (minimal)
GPT-4.1
DeepSeek V3.1
gpt-oss-120B(high)
Grok CodeFast 1
gpt-oss-20B(high)
LlamaNemotronSuper 49B v1.5
GLM-4.5
EXAONE 4.032B
Mistral Medium3.1
Llama 4Maverick
Kimi K2 0905
Solar Pro2
46%
44%
43%
43%
42%
41%
40%
40%
39%
39%
39%
38%
37%
36%
36%
35%
35%
35%
34%
34%
33%
31%
30%
IFBench (Instruction Following)
GPT-5(high)
gpt-oss-120B(high)
gpt-oss-20B(high)
Claude 4.1Opus
Claude 4Sonnet
Grok 4
Qwen3 235B2507
Grok 4Fast
Gemini 2.5Flash
Gemini 2.5Pro
GPT-5 (minimal)
GLM-4.5
GPT-4.1
Llama 4Maverick
Kimi K2 0905
DeepSeekV3.1
Grok CodeFast 1
Mistral Medium3.1
DeepSeekR1 0528
DeepSeek V3.1
Solar Pro2
LlamaNemotronSuper 49B v1.5
EXAONE 4.032B
73%
69%
61%
55%
55%
54%
51%
51%
50%
49%
46%
44%
43%
43%
42%
42%
41%
40%
40%
38%
37%
37%
36%
AIME 2025 (Competition Math)
GPT-5(high)
gpt-oss-120B(high)
Grok 4
Qwen3 235B2507
DeepSeekV3.1
Grok 4Fast
Gemini 2.5Pro
Claude 4.1Opus
EXAONE 4.032B
LlamaNemotronSuper 49B v1.5
DeepSeekR1 0528
Claude 4Sonnet
GLM-4.5
Gemini 2.5Flash
gpt-oss-20B(high)
Solar Pro2
Kimi K2 0905
DeepSeek V3.1
Grok CodeFast 1
Mistral Medium3.1
GPT-4.1
GPT-5 (minimal)
Llama 4Maverick
94%
93%
93%
91%
90%
90%
88%
80%
80%
77%
76%
74%
74%
73%
62%
61%
57%
50%
43%
38%
35%
32%
19%
AA-LCR (Long Context Reasoning)
GPT-5(high)
Grok 4
Qwen3 235B2507
Claude 4.1Opus
Gemini 2.5Pro
Claude 4Sonnet
Grok 4Fast
Gemini 2.5Flash
GPT-4.1
DeepSeekR1 0528
DeepSeekV3.1
Kimi K2 0905
gpt-oss-120B(high)
Grok CodeFast 1
GLM-4.5
Llama 4Maverick
DeepSeek V3.1
LlamaNemotronSuper 49B v1.5
GPT-5 (minimal)
Mistral Medium3.1
gpt-oss-20B(high)
EXAONE 4.032B
76%
68%
67%
66%
66%
65%
65%
62%
61%
55%
53%
52%
51%
48%
48%
46%
45%
34%
25%
20%
19%
14%
Terminal-Bench Hard (Agentic Coding & Terminal Use)
Grok 4
Claude 4.1Opus
GPT-5(high)
Claude 4Sonnet
Gemini 2.5Pro
DeepSeekV3.1
DeepSeek V3.1
Kimi K2 0905
gpt-oss-120B(high)
GLM-4.5
GPT-5 (minimal)
Grok 4Fast
Grok CodeFast 1
DeepSeekR1 0528
GPT-4.1
Gemini 2.5Flash
Qwen3 235B2507
Mistral Medium3.1
Llama 4Maverick
gpt-oss-20B(high)
LlamaNemotronSuper 49B v1.5
EXAONE 4.032B
Solar Pro2
38%
32%
31%
30%
25%
24%
23%
23%
22%
21%
18%
18%
16%
15%
13%
13%
13%
10%
6%
6%
5%
4%
3%
ùúè¬≤-Bench Telecom (Agentic Tool Use)
GPT-5(high)
Grok CodeFast 1
Grok 4
Kimi K2 0905
Claude 4.1Opus
GPT-5 (minimal)
gpt-oss-120B(high)
Grok 4Fast
Claude 4Sonnet
Gemini 2.5Pro
Qwen3 235B2507
gpt-oss-20B(high)
GPT-4.1
Mistral Medium3.1
DeepSeekV3.1
DeepSeekR1 0528
DeepSeek V3.1
Gemini 2.5Flash
Solar Pro2
LlamaNemotronSuper 49B v1.5
GLM-4.5
Llama 4Maverick
EXAONE 4.032B
85%
76%
75%
73%
71%
67%
66%
66%
65%
54%
53%
50%
47%
41%
37%
37%
35%
32%
28%
28%
25%
18%
17%
10 of 13 quality evaluations selected
23 of 275 models selected
+ Add model from specific provider
While model intelligence generally translates across use cases, specific evaluations may be more relevant for certain use cases.
Artificial Analysis Intelligence Index: Combination metric covering multiple dimensions of intelligence - the simplest way to compare how smart models are. Version 3.0 was released in September 2025 and includes: MMLU-Pro, GPQA Diamond, Humanity's Last Exam, LiveCodeBench, SciCode, AIME 2025, IFBench, AA-LCR, Terminal-Bench Hard, ùúè¬≤-Bench Telecom. See Intelligence Index methodology for further details, including a breakdown of each evaluation and how we run them.
Output Tokens Used to Run Artificial Analysis Intelligence Index
Tokens used to run all evaluations in the Artificial Analysis Intelligence Index
Answer Tokens
Reasoning Tokens
Artificial Analysis
Grok 4
gpt-oss-120B(high)
LlamaNemotronSuper 49B v1.5
Qwen3 235B2507
GLM-4.5
EXAONE 4.032B
Gemini 2.5Pro
DeepSeekR1 0528
Gemini 2.5Flash
Grok CodeFast 1
GPT-5(high)
DeepSeekV3.1
Grok 4Fast
Solar Pro2
gpt-oss-20B(high)
Claude 4Sonnet
Claude 4.1Opus
Kimi K2 0905
Llama 4Maverick
DeepSeek V3.1
Mistral Medium3.1
GPT-4.1
GPT-5 (minimal)
120M
110M
110M
110M
100M
100M
100M
99M
93M
87M
87M
63M
61M
56M
56M
43M
30M
16M
15M
14M
12M
7.4M
4.4M
120M
110M
100M
100M
96M
96M
89M
91M
78M
84M
84M
57M
57M
50M
53M
37M
23M
12M
16M
23 of 275 models selected
+ Add model from specific provider
Artificial Analysis Intelligence Index Tokens Use: The number of tokens required to run all evaluations in the Artificial Analysis Intelligence Index (excluding repeats).
Cost to Run Artificial Analysis Intelligence Index
Cost (USD) to run all evaluations in the Artificial Analysis Intelligence Index
Input Cost
Output Cost
Reasoning Cost
Artificial Analysis
Claude 4.1Opus
Grok 4
Gemini 2.5Pro
Qwen3 235B2507
GPT-5(high)
Claude 4Sonnet
GLM-4.5
Gemini 2.5Flash
DeepSeekR1 0528
GPT-4.1
DeepSeekV3.1
Grok CodeFast 1
EXAONE 4.032B
GPT-5 (minimal)
Kimi K2 0905
gpt-oss-120B(high)
LlamaNemotronSuper 49B v1.5
Mistral Medium3.1
Grok 4Fast
Solar Pro2
Llama 4Maverick
DeepSeek V3.1
gpt-oss-20B(high)
$3124
$1888
$1068
$934
$927
$827
$274
$248
$235
$168
$168
$139
$132
$117
$112
$75
$48
$44
$40
$39
$33
$32
$13
$859
$1754
$1725
$888
$839
$837
$549
$511
23 of 275 models selected
+ Add model from specific provider
Cost to Run Artificial Analysis Intelligence Index: The cost to run the evaluations in the Artificial Analysis Intelligence Index, calculated using the model's input and output token pricing and the number of tokens used across evaluations (excluding repeats).
Intelligence vs. Cost to Run Artificial Analysis Intelligence Index
Artificial Analysis Intelligence Index; Cost to Run Intelligence Index
Most attractive quadrant
Alibaba
Anthropic
DeepSeek
Google
LG AI Research
Meta
Mistral
Moonshot AI
NVIDIA
OpenAI
Upstage
xAI
Z AI
Artificial Analysis
4
8
16
32
64
128
256
512
1024
2048
4096
Cost to Run Intelligence Index (USD, Log Scale)
35
40
45
50
55
60
65
Artificial Analysis Intelligence Index
gpt-oss-20B (high)
gpt-oss-20B (high)
Llama 4 Maverick
Llama 4 Maverick
Solar Pro 2
Solar Pro 2
DeepSeek V3.1
DeepSeek V3.1
Mistral Medium 3.1
Mistral Medium 3.1
Llama Nemotron Super 49B v1.5
Llama Nemotron Super 49B v1.5
Grok 4 Fast
Grok 4 Fast
gpt-oss-120B (high)
gpt-oss-120B (high)
Kimi K2 0905
Kimi K2 0905
GPT-5 (minimal)
GPT-5 (minimal)
EXAONE 4.0 32B
EXAONE 4.0 32B
Grok Code Fast 1
Grok Code Fast 1
GPT-4.1
GPT-4.1
DeepSeek V3.1
DeepSeek V3.1
DeepSeek R1 0528
DeepSeek R1 0528
Gemini 2.5 Flash
Gemini 2.5 Flash
GLM-4.5
GLM-4.5
Claude 4 Sonnet
Claude 4 Sonnet
GPT-5 (high)
GPT-5 (high)
Qwen3 235B 2507
Qwen3 235B 2507
Gemini 2.5 Pro
Gemini 2.5 Pro
Grok 4
Grok 4
Claude 4.1 Opus
Claude 4.1 Opus
23 of 275 models selected
+ Add model from specific provider
Cost to Run Artificial Analysis Intelligence Index: The cost to run the evaluations in the Artificial Analysis Intelligence Index, calculated using the model's input and output token pricing and the number of tokens used across evaluations (excluding repeats).
Artificial Analysis Intelligence Index: Combination metric covering multiple dimensions of intelligence - the simplest way to compare how smart models are. Version 3.0 was released in September 2025 and includes: MMLU-Pro, GPQA Diamond, Humanity's Last Exam, LiveCodeBench, SciCode, AIME 2025, IFBench, AA-LCR, Terminal-Bench Hard, ùúè¬≤-Bench Telecom. See Intelligence Index methodology for further details, including a breakdown of each evaluation and how we run them.
Speed & Latency

Comparison of first-party API performance

Output Speed
Output Tokens per Second; Higher is better
Artificial Analysis
Grok CodeFast 1
Grok 4Fast
gpt-oss-120B(high)
Gemini 2.5Flash
gpt-oss-20B(high)
GPT-5(high)
Gemini 2.5Pro
Llama 4Maverick
GPT-5 (minimal)
Solar Pro2
GPT-4.1
LlamaNemotronSuper 49B v1.5
Qwen3 235B2507
Mistral Medium3.1
EXAONE 4.032B
Claude 4Sonnet
GLM-4.5
Kimi K2 0905
Grok 4
Claude 4.1Opus
DeepSeekV3.1
DeepSeekR1 0528
DeepSeek V3.1
21
20
20
313
256
254
252
247
171
154
140
131
106
95
79
67
67
57
56
54
51
45
42
23 of 275 models selected
+ Add model from specific provider
Output Speed: Tokens per second received while the model is generating tokens (ie. after first chunk has been received from the API for models which support streaming).
Figures represent performance of the model's first-party API (e.g. OpenAI for o1) or the median across providers where a first-party API is not available (e.g. Meta's Llama models).
Latency: Time To First Answer Token
Seconds to First Answer Token Received; Accounts for Reasoning Model 'Thinking' time
Input processing
Thinking (reasoning models, when applicable)
Artificial Analysis
Llama 4Maverick
Mistral Medium3.1
Kimi K2 0905
GPT-4.1
GPT-5 (minimal)
DeepSeek V3.1
Grok 4Fast
Grok CodeFast 1
gpt-oss-120B(high)
gpt-oss-20B(high)
Gemini 2.5Flash
Grok 4
Solar Pro2
LlamaNemotronSuper 49B v1.5
Gemini 2.5Pro
Qwen3 235B2507
EXAONE 4.032B
Claude 4Sonnet
GLM-4.5
Claude 4.1Opus
GPT-5(high)
DeepSeekV3.1
DeepSeekR1 0528
0.4
0.4
0.4
0.5
1
2.7
3.5
7.4
8.4
8.5
11.7
14.1
20.2
25.8
28.8
30.8
35.7
37.1
37.5
50.1
51.2
99.9
100.6
18.8
25.3
29.7
35.4
36
36.9
47.9
97.1
97.7
23 of 275 models selected
+ Add model from specific provider
Time To First Answer Token: Time to first answer token received, in seconds, after API request sent. For reasoning models, this includes the 'thinking' time of the model before providing an answer. For models which do not support streaming, this represents time to receive the completion.
End-to-End Response Time
Seconds to Output 500 Tokens, including reasoning model 'thinking' time; Lower is better
'Thinking' time (reasoning models)
Input processing time
Outputting time
Artificial Analysis
Llama 4Maverick
GPT-5 (minimal)
Grok 4Fast
GPT-4.1
Mistral Medium3.1
Grok CodeFast 1
Kimi K2 0905
gpt-oss-120B(high)
gpt-oss-20B(high)
Gemini 2.5Flash
Solar Pro2
Grok 4
DeepSeek V3.1
Gemini 2.5Pro
LlamaNemotronSuper 49B v1.5
Qwen3 235B2507
EXAONE 4.032B
Claude 4Sonnet
GLM-4.5
GPT-5(high)
Claude 4.1Opus
DeepSeekV3.1
DeepSeekR1 0528
3.9
4.8
5.5
5.8
7.9
9
10.3
10.3
10.6
13.7
24.9
25.3
27.7
32.1
32.1
38.3
44.6
46.1
46.7
54.2
62.1
124.2
125
14.1
28.8
51.2
18.8
25.3
29.7
35.4
36
36.9
47.9
97.1
97.7
11.2
24.9
12
24.3
24.4
23 of 275 models selected
+ Add model from specific provider
End-to-End Response Time: Seconds to receive a 500 token response. Key components:
Input time: Time to receive the first response token
Thinking time (only for reasoning models): Time reasoning models spend outputting tokens to reason prior to providing an answer. Amount of tokens based on the average reasoning tokens across a diverse set of 60 prompts¬†(methodology details).
Answer time: Time to generate 500 output tokens, based on output speed
Figures represent performance of the model's first-party API (e.g. OpenAI for o1) or the median across providers where a first-party API is not available (e.g. Meta's Llama models).
Intelligence vs. Output Speed
Artificial Analysis Intelligence Index; Output Speed: Output Tokens per Second
Most attractive quadrant
Alibaba
Anthropic
DeepSeek
Google
LG AI Research
Meta
Mistral
Moonshot AI
NVIDIA
OpenAI
Upstage
xAI
Z AI
Artificial Analysis
0
50
100
150
200
250
300
Output Speed (Output Tokens per Second)
35
40
45
50
55
60
65
Artificial Analysis Intelligence Index
DeepSeek V3.1
DeepSeek V3.1
DeepSeek R1 0528
DeepSeek R1 0528
DeepSeek V3.1
DeepSeek V3.1
EXAONE 4.0 32B
EXAONE 4.0 32B
Kimi K2 0905
Kimi K2 0905
Claude 4.1 Opus
Claude 4.1 Opus
GLM-4.5
GLM-4.5
Mistral Medium 3.1
Mistral Medium 3.1
Grok 4
Grok 4
Claude 4 Sonnet
Claude 4 Sonnet
Qwen3 235B 2507
Qwen3 235B 2507
Llama Nemotron Super 49B v1.5
Llama Nemotron Super 49B v1.5
GPT-4.1
GPT-4.1
Solar Pro 2
Solar Pro 2
GPT-5 (minimal)
GPT-5 (minimal)
Llama 4 Maverick
Llama 4 Maverick
Gemini 2.5 Pro
Gemini 2.5 Pro
GPT-5 (high)
GPT-5 (high)
gpt-oss-20B (high)
gpt-oss-20B (high)
Gemini 2.5 Flash
Gemini 2.5 Flash
gpt-oss-120B (high)
gpt-oss-120B (high)
Grok 4 Fast
Grok 4 Fast
Grok Code Fast 1
Grok Code Fast 1
23 of 275 models selected
+ Add model from specific provider
Artificial Analysis Intelligence Index: Combination metric covering multiple dimensions of intelligence - the simplest way to compare how smart models are. Version 3.0 was released in September 2025 and includes: MMLU-Pro, GPQA Diamond, Humanity's Last Exam, LiveCodeBench, SciCode, AIME 2025, IFBench, AA-LCR, Terminal-Bench Hard, ùúè¬≤-Bench Telecom. See Intelligence Index methodology for further details, including a breakdown of each evaluation and how we run them.
Output Speed: Tokens per second received while the model is generating tokens (ie. after first chunk has been received from the API for models which support streaming).
Figures represent performance of the model's first-party API (e.g. OpenAI for o1) or the median across providers where a first-party API is not available (e.g. Meta's Llama models).
Price
Pricing: Input and Output Prices
Price: USD per 1M Tokens
Input price
Output price
Artificial Analysis
gpt-oss-20B(high)
LlamaNemotronSuper 49B v1.5
Grok 4Fast
gpt-oss-120B(high)
Solar Pro2
Llama 4Maverick
DeepSeek V3.1
EXAONE 4.032B
Grok CodeFast 1
Mistral Medium3.1
DeepSeekV3.1
DeepSeekR1 0528
GLM-4.5
Gemini 2.5Flash
Kimi K2 0905
Qwen3 235B2507
GPT-4.1
GPT-5 (minimal)
GPT-5(high)
Gemini 2.5Pro
Claude 4Sonnet
Grok 4
Claude 4.1Opus
0.05
0.1
0.2
0.15
0.5
0.24
0.27
0.6
0.2
0.4
0.55
0.55
0.59
0.3
0.99
0.7
2
1.25
1.25
1.25
3
3
15
0.2
0.4
0.5
0.6
0.5
0.85
1.1
1
1.5
2
2.19
2.19
2.19
2.5
2.75
8.4
8
10
10
10
15
15
75
23 of 275 models selected
+ Add model from specific provider
Input Price: Price per token included in the request/message sent to the API, represented as USD per million Tokens.
Figures represent performance of the model's first-party API (e.g. OpenAI for o1) or the median across providers where a first-party API is not available (e.g. Meta's Llama models).
Intelligence vs. Price (Log Scale)
Artificial Analysis Intelligence Index; Price: USD per 1M Tokens; Inspired by prior analysis by Swyx
Most attractive quadrant
Alibaba
Anthropic
DeepSeek
Google
LG AI Research
Meta
Mistral
Moonshot AI
NVIDIA
OpenAI
Upstage
xAI
Z AI
Artificial Analysis
$64.00
$32.00
$16.00
$8.00
$4.00
$2.00
$1.00
$0.50
$0.25
$0.13
$0.06
$0.03
$0.02
Price (USD per M Tokens, Log Scale, More Expensive to Cheaper)
35
40
45
50
55
60
65
Artificial Analysis Intelligence Index
Mistral Medium 3.1
Mistral Medium 3.1
Llama 4 Maverick
Llama 4 Maverick
Solar Pro 2
Solar Pro 2
EXAONE 4.0 32B
EXAONE 4.0 32B
GPT-4.1
GPT-4.1
GPT-5 (minimal)
GPT-5 (minimal)
gpt-oss-20B (high)
gpt-oss-20B (high)
DeepSeek V3.1
DeepSeek V3.1
Llama Nemotron Super 49B v1.5
Llama Nemotron Super 49B v1.5
Grok Code Fast 1
Grok Code Fast 1
GLM-4.5
GLM-4.5
Kimi K2 0905
Kimi K2 0905
Gemini 2.5 Flash
Gemini 2.5 Flash
DeepSeek R1 0528
DeepSeek R1 0528
DeepSeek V3.1
DeepSeek V3.1
Claude 4 Sonnet
Claude 4 Sonnet
Qwen3 235B 2507
Qwen3 235B 2507
gpt-oss-120B (high)
gpt-oss-120B (high)
Gemini 2.5 Pro
Gemini 2.5 Pro
Grok 4 Fast
Grok 4 Fast
Grok 4
Grok 4
Claude 4.1 Opus
Claude 4.1 Opus
GPT-5 (high)
GPT-5 (high)
23 of 275 models selected
+ Add model from specific provider
While higher intelligence models are typically more expensive, they do not all follow the same price-quality curve.
Artificial Analysis Intelligence Index: Combination metric covering multiple dimensions of intelligence - the simplest way to compare how smart models are. Version 3.0 was released in September 2025 and includes: MMLU-Pro, GPQA Diamond, Humanity's Last Exam, LiveCodeBench, SciCode, AIME 2025, IFBench, AA-LCR, Terminal-Bench Hard, ùúè¬≤-Bench Telecom. See Intelligence Index methodology for further details, including a breakdown of each evaluation and how we run them.
Price: Price per token, represented as USD per million Tokens. Price is a blend of Input & Output token prices (3:1 ratio).
Figures represent performance of the model's first-party API (e.g. OpenAI for o1) or the median across providers where a first-party API is not available (e.g. Meta's Llama models).
NEW
Hardware Benchmarking

Comprehensive benchmarking of GPUs for language model inference

Video Arena & Leaderboard

Compare leading Text to Video and Image to Video models

Image Arena & Leaderboard

Compare leading Image Generation and Image Editing models

Speech Arena & Leaderboard

Compare leading Text to Speech models

API Provider Performance
gpt-oss-120B (high)
gpt-oss-20B (high)
GPT-5 (minimal)
GPT-5 (high)
GPT-4.1
Llama 4 Maverick
Gemini 2.5 Flash
Gemini 2.5 Pro
Claude 4.1 Opus
Claude 4 Sonnet
Mistral Medium 3.1
DeepSeek V3.1
DeepSeek V3.1
DeepSeek R1 0528
Grok 4
Grok 4 Fast
Grok Code Fast 1
Solar Pro 2
Llama Nemotron Super 49B v1.5
Kimi K2 0905
EXAONE 4.0 32B
GLM-4.5
Qwen3 235B 2507
More Information: gpt-oss-120B (high) selected
Output Speed vs. Price: gpt-oss-120B (high)
Output Speed: Output Tokens per Second, Price: USD per 1M Tokens; 1,000 Input Tokens
Most attractive quadrant
Amazon Bedrock
Cerebras
Clarifai
Cloudflare
CompactifAI
Databricks
Deepinfra
Fireworks
GMI
Google Vertex
Groq
Microsoft Azure
Nebius Base
Novita
Parasail
SambaNova
Together.ai
Artificial Analysis
$0.00
$0.10
$0.20
$0.30
$0.40
$0.50
$0.60
$0.70
$0.80
$0.90
$1.00
$1.10
$1.20
Price (USD per 1M Tokens)
0
500
1000
1500
2000
2500
3000
3500
Output Speed (Output Tokens per Second)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
gpt-oss-120B (high)
17 of 17 providers selected
Smaller, emerging providers are offering high output speed and at competitive prices.
Price: Price per token, represented as USD per million Tokens. Price is a blend of Input & Output token prices (3:1 ratio).
Output Speed: Tokens per second received while the model is generating tokens (ie. after first chunk has been received from the API for models which support streaming).
Median: Figures represent median (P50) measurement over the past 72 hours to reflect sustained changes in performance.
Pricing (Input and Output Prices): gpt-oss-120B (high)
Price: USD per 1M Tokens; Lower is better; 1,000 Input Tokens
Input price
Output price
Artificial Analysis
CompactifAI
Clarifai
Deepinfra
GMI
Novita
Parasail
Amazon
NebiusBase
GoogleVertex
Azure
Fireworks
Databricks
Together.ai
SambaNova
Groq
Cerebras
Cloudflare
0.05
0.09
0.09
0.09
0.1
0.15
0.15
0.15
0.15
0.15
0.15
0.15
0.15
0.22
0.15
0.25
0.35
0.23
0.36
0.45
0.5
0.5
0.6
0.6
0.6
0.6
0.6
0.6
0.6
0.6
0.59
0.75
0.69
0.75
17 of 17 providers selected
The relative importance of input vs. output token prices varies by use case. E.g. Generation tasks are typically more output token weighted while document processing tasks are more input token weighted.
Input Price: Price per token included in the request/message sent to the API, represented as USD per million Tokens.
Output Price: Price per token generated by the model (received from the API), represented as USD per million Tokens.
Output Speed: gpt-oss-120B (high)
Output Speed: Output Tokens per Second; 1,000 Input Tokens
Artificial Analysis
Cerebras
Clarifai
SambaNova
Groq
Fireworks
GoogleVertex
Azure
Together.ai
Novita
Amazon
Databricks
GMI
CompactifAI
NebiusBase
Parasail
Deepinfra
Cloudflare
248
229
200
192
186
174
171
152
61
3219
634
543
493
409
406
314
292
248
229
17 of 17 providers selected
Output Speed: Tokens per second received while the model is generating tokens (ie. after first chunk has been received from the API for models which support streaming).
Figures represent performance of the model's first-party API (e.g. OpenAI for o1) or the median across providers where a first-party API is not available (e.g. Meta's Llama models).
Output Speed, Over Time: gpt-oss-120B (high)
Output Tokens per Second; Higher is better; 1,000 Input Tokens
Amazon
Azure
Cerebras
Clarifai
Cloudflare
CompactifAI
Databricks
Deepinfra
Fireworks
GMI
Google Vertex
Groq
Nebius Base
Novita
Parasail
SambaNova
Together.ai
Jan 01
Jan 02
Aug 10
Aug 17
Aug 24
Aug 31
Sep 07
Sep 14
Sep 21
0
500
1000
1500
2000
2500
3000
3500
Artificial Analysis
17 of 17 providers selected
Smaller, emerging providers offer high output speed, though precise speeds delivered vary day-to-day.
Output Speed: Tokens per second received while the model is generating tokens (ie. after first chunk has been received from the API for models which support streaming).
Over time measurement: Median measurement per day, based on 8 measurements each day at different times. Labels represent start of week's measurements.
See more information on any of our supported models
MODEL NAME	CREATOR	LICENSE	CONTEXT WINDOW	FURTHER ANALYSIS

		

GPT-4o mini
	
OpenAI
	
Proprietary
	
128k
	

Model

API Providers



GPT-5 nano (minimal)
	
OpenAI
	
Proprietary
	
400k
	

Model

API Providers



gpt-oss-120B (high)
	
OpenAI
	
Open
	
131k
	

Model

API Providers



gpt-oss-20B (high)
	
OpenAI
	
Open
	
131k
	

Model

API Providers



o4-mini (high)
	
OpenAI
	
Proprietary
	
200k
	

Model

API Providers



GPT-4.1 nano
	
OpenAI
	
Proprietary
	
1m
	

Model

API Providers



GPT-5 (minimal)
	
OpenAI
	
Proprietary
	
400k
	

Model

API Providers



GPT-5 (medium)
	
OpenAI
	
Proprietary
	
400k
	

Model

API Providers



GPT-5 (high)
	
OpenAI
	
Proprietary
	
400k
	

Model

API Providers



GPT-4.1
	
OpenAI
	
Proprietary
	
1m
	

Model

API Providers



GPT-5 mini (minimal)
	
OpenAI
	
Proprietary
	
400k
	

Model

API Providers



o3
	
OpenAI
	
Proprietary
	
200k
	

Model

API Providers



GPT-4.1 mini
	
OpenAI
	
Proprietary
	
1m
	

Model

API Providers



GPT-4o (ChatGPT)
	
OpenAI
	
Proprietary
	
128k
	

Model

API Providers



o3-mini (high)
	
OpenAI
	
Proprietary
	
200k
	

Model

API Providers



GPT-5 mini (medium)
	
OpenAI
	
Proprietary
	
400k
	

Model

API Providers



GPT-5 (low)
	
OpenAI
	
Proprietary
	
400k
	

Model

API Providers



o3-mini
	
OpenAI
	
Proprietary
	
200k
	

Model

API Providers



GPT-5 nano (high)
	
OpenAI
	
Proprietary
	
400k
	

Model

API Providers



GPT-5 mini (high)
	
OpenAI
	
Proprietary
	
400k
	

Model

API Providers



o3-pro
	
OpenAI
	
Proprietary
	
200k
	

Model

API Providers



GPT-5 nano (medium)
	
OpenAI
	
Proprietary
	
400k
	

Model

API Providers



o1
	
OpenAI
	
Proprietary
	
200k
	

Model

API Providers



o1-preview
	
OpenAI
	
Proprietary
	
128k
	

Model

API Providers



o1-mini
	
OpenAI
	
Proprietary
	
128k
	

Model

API Providers



GPT-4o (Aug '24)
	
OpenAI
	
Proprietary
	
128k
	

Model

API Providers



GPT-4o (May '24)
	
OpenAI
	
Proprietary
	
128k
	

Model

API Providers



GPT-4 Turbo
	
OpenAI
	
Proprietary
	
128k
	

Model

API Providers



GPT-4o (Nov '24)
	
OpenAI
	
Proprietary
	
128k
	

Model

API Providers



GPT-3.5 Turbo
	
OpenAI
	
Proprietary
	
4k
	

Model

API Providers



GPT-4.5 (Preview)
	
OpenAI
	
Proprietary
	
128k
	

Model

API Providers



GPT-4o (March 2025, chatgpt-4o-latest)
	
OpenAI
	
Proprietary
	
128k
	

Model

API Providers



o1-pro
	
OpenAI
	
Proprietary
	
200k
	

Model

API Providers



GPT-4o Realtime (Dec '24)
	
OpenAI
	
Proprietary
	
128k
	

Model

API Providers



GPT-4
	
OpenAI
	
Proprietary
	
8k
	

Model

API Providers



GPT-4o mini Realtime (Dec '24)
	
OpenAI
	
Proprietary
	
128k
	

Model

API Providers



GPT-3.5 Turbo (0613)
	
OpenAI
	
Proprietary
	
4k
	

Model

API Providers



		

Grok-1
	
xAI
	
Open
	
8k
	

Model

API Providers



Grok 3 mini Reasoning (Low)
	
xAI
	
Proprietary
	
1m
	

Model

API Providers



Grok 4
	
xAI
	
Proprietary
	
256k
	

Model

API Providers



Grok 4 Fast (Reasoning)
	
xAI
	
Proprietary
	
2m
	

Model

API Providers



Grok Code Fast 1
	
xAI
	
Proprietary
	
256k
	

Model

API Providers



Grok 3 mini Reasoning (high)
	
xAI
	
Proprietary
	
1m
	

Model

API Providers



Grok 3 Reasoning Beta
	
xAI
	
Proprietary
	
1m
	

Model

API Providers



Grok 3
	
xAI
	
Proprietary
	
1m
	

Model

API Providers



Grok 4 Fast
	
xAI
	
Proprietary
	
2m
	

Model

API Providers



Grok Beta
	
xAI
	
Proprietary
	
128k
	

Model

API Providers



Grok 2 (Dec '24)
	
xAI
	
Open
	
131k
	

Model

API Providers



		

PALM-2
	
Google
	
Proprietary
	
8k
	

Model

API Providers



Gemma 3 27B Instruct
	
Google
	
Open
	
128k
	

Model

API Providers



Gemini 2.5 Flash-Lite
	
Google
	
Proprietary
	
1m
	

Model

API Providers



Gemma 3 4B Instruct
	
Google
	
Open
	
128k
	

Model

API Providers



Gemma 3n E2B Instruct
	
Google
	
Open
	
32k
	

Model

API Providers



Gemma 3 1B Instruct
	
Google
	
Open
	
32k
	

Model

API Providers



Gemini 2.5 Flash (Reasoning)
	
Google
	
Proprietary
	
1m
	

Model

API Providers



Gemini 2.5 Flash
	
Google
	
Proprietary
	
1m
	

Model

API Providers



Gemini 2.5 Flash-Lite (Reasoning)
	
Google
	
Proprietary
	
1m
	

Model

API Providers



Gemini 2.5 Pro
	
Google
	
Proprietary
	
1m
	

Model

API Providers



Gemma 3 12B Instruct
	
Google
	
Open
	
128k
	

Model

API Providers



Gemma 3n E4B Instruct
	
Google
	
Open
	
32k
	

Model

API Providers



Gemini 2.0 Pro Experimental (Feb '25)
	
Google
	
Proprietary
	
2m
	

Model

API Providers



Gemini 2.0 Flash (experimental)
	
Google
	
Proprietary
	
1m
	

Model

API Providers



Gemini 1.5 Pro (Sep '24)
	
Google
	
Proprietary
	
2m
	

Model

API Providers



Gemini 2.0 Flash-Lite (Preview)
	
Google
	
Proprietary
	
1m
	

Model

API Providers



Gemini 2.0 Flash (Feb '25)
	
Google
	
Proprietary
	
1m
	

Model

API Providers



Gemini 1.5 Flash (Sep '24)
	
Google
	
Proprietary
	
1m
	

Model

API Providers



Gemma 2 27B
	
Google
	
Open
	
8k
	

Model

API Providers



Gemma 2 9B
	
Google
	
Open
	
8k
	

Model

API Providers



Gemini 1.5 Flash-8B
	
Google
	
Proprietary
	
1m
	

Model

API Providers



Gemma 3n E4B Instruct Preview (May '25)
	
Google
	
Open
	
32k
	

Model

API Providers



Gemini 1.5 Flash (May '24)
	
Google
	
Proprietary
	
1m
	

Model

API Providers



Gemini 2.0 Flash Thinking Experimental (Jan '25)
	
Google
	
Proprietary
	
1m
	

Model

API Providers



Gemini 2.0 Flash-Lite (Feb '25)
	
Google
	
Proprietary
	
1m
	

Model

API Providers



Gemini 2.5 Flash Preview (Reasoning)
	
Google
	
Proprietary
	
1m
	

Model

API Providers



Gemini 2.0 Flash Thinking Experimental (Dec '24)
	
Google
	
Proprietary
	
2m
	

Model

API Providers



Gemini 1.5 Pro (May '24)
	
Google
	
Proprietary
	
2m
	

Model

API Providers



Gemini 2.5 Flash Preview
	
Google
	
Proprietary
	
1m
	

Model

API Providers



Gemini 1.0 Pro
	
Google
	
Proprietary
	
33k
	

Model

API Providers



Gemini 2.5 Pro Preview (May' 25)
	
Google
	
Proprietary
	
1m
	

Model

API Providers



Gemini 2.5 Pro Preview (Mar' 25)
	
Google
	
Proprietary
	
1m
	

Model

API Providers



Gemini 1.0 Ultra
	
Google
	
Proprietary
	
33k
	

Model

API Providers



		

Llama 3.3 Instruct 70B
	
Meta
	
Open
	
128k
	

Model

API Providers



Llama 3.1 Instruct 405B
	
Meta
	
Open
	
128k
	

Model

API Providers



Llama 3.2 Instruct 90B (Vision)
	
Meta
	
Open
	
128k
	

Model

API Providers



Llama 3.2 Instruct 11B (Vision)
	
Meta
	
Open
	
128k
	

Model

API Providers



Llama 4 Scout
	
Meta
	
Open
	
10m
	

Model

API Providers



Llama 4 Maverick
	
Meta
	
Open
	
1m
	

Model

API Providers



Llama 65B
	
Meta
	
Open
	
2k
	

Model

API Providers



Llama 3.1 Instruct 70B
	
Meta
	
Open
	
128k
	

Model

API Providers



Llama 3.1 Instruct 8B
	
Meta
	
Open
	
128k
	

Model

API Providers



Llama 3.2 Instruct 3B
	
Meta
	
Open
	
128k
	

Model

API Providers



Llama 3 Instruct 70B
	
Meta
	
Open
	
8k
	

Model

API Providers



Llama 3 Instruct 8B
	
Meta
	
Open
	
8k
	

Model

API Providers



Llama 3.2 Instruct 1B
	
Meta
	
Open
	
128k
	

Model

API Providers



Llama 2 Chat 13B
	
Meta
	
Open
	
4k
	

Model

API Providers



Llama 2 Chat 70B
	
Meta
	
Open
	
4k
	

Model

API Providers



Llama 2 Chat 7B
	
Meta
	
Open
	
4k
	

Model

API Providers



		

Claude 4 Opus
	
Anthropic
	
Proprietary
	
200k
	

Model

API Providers



Claude 4.1 Opus (Extended Thinking)
	
Anthropic
	
Proprietary
	
200k
	

Model

API Providers



Claude 4 Sonnet
	
Anthropic
	
Proprietary
	
1m
	

Model

API Providers



Claude 4.1 Opus
	
Anthropic
	
Proprietary
	
200k
	

Model

API Providers



Claude 4 Sonnet (Extended Thinking)
	
Anthropic
	
Proprietary
	
1m
	

Model

API Providers



Claude 4 Opus (Extended Thinking)
	
Anthropic
	
Proprietary
	
200k
	

Model

API Providers



Claude 3.5 Sonnet (Oct '24)
	
Anthropic
	
Proprietary
	
200k
	

Model

API Providers



Claude 3.5 Sonnet (June '24)
	
Anthropic
	
Proprietary
	
200k
	

Model

API Providers



Claude 3 Opus
	
Anthropic
	
Proprietary
	
200k
	

Model

API Providers



Claude 3.5 Haiku
	
Anthropic
	
Proprietary
	
200k
	

Model

API Providers



Claude 3 Sonnet
	
Anthropic
	
Proprietary
	
200k
	

Model

API Providers



Claude 3 Haiku
	
Anthropic
	
Proprietary
	
200k
	

Model

API Providers



Claude Instant
	
Anthropic
	
Proprietary
	
100k
	

Model

API Providers



Claude 3.7 Sonnet (Extended Thinking)
	
Anthropic
	
Proprietary
	
200k
	

Model

API Providers



Claude 3.7 Sonnet (Standard)
	
Anthropic
	
Proprietary
	
200k
	

Model

API Providers



Claude 2.0
	
Anthropic
	
Proprietary
	
100k
	

Model

API Providers



Claude 2.1
	
Anthropic
	
Proprietary
	
200k
	

Model

API Providers



		

Ministral 8B
	
Mistral
	
Open
	
128k
	

Model

API Providers



Ministral 3B
	
Mistral
	
Proprietary
	
128k
	

Model

API Providers



Mistral Medium 3
	
Mistral
	
Proprietary
	
128k
	

Model

API Providers



Mistral Small 3.2
	
Mistral
	
Open
	
128k
	

Model

API Providers



Devstral Medium
	
Mistral
	
Proprietary
	
256k
	

Model

API Providers



Devstral Small (Jul '25)
	
Mistral
	
Open
	
256k
	

Model

API Providers



Magistral Medium 1.2
	
Mistral
	
Proprietary
	
128k
	

Model

API Providers



Mistral Medium 3.1
	
Mistral
	
Proprietary
	
128k
	

Model

API Providers



Magistral Small 1.2
	
Mistral
	
Open
	
128k
	

Model

API Providers



Magistral Medium 1
	
Mistral
	
Proprietary
	
40k
	

Model

API Providers



Magistral Small 1
	
Mistral
	
Open
	
40k
	

Model

API Providers



Codestral (Jan '25)
	
Mistral
	
Proprietary
	
256k
	

Model

API Providers



Mistral Large 2 (Nov '24)
	
Mistral
	
Open
	
128k
	

Model

API Providers



Mistral Large 2 (Jul '24)
	
Mistral
	
Open
	
128k
	

Model

API Providers



Pixtral Large
	
Mistral
	
Open
	
128k
	

Model

API Providers



Mistral Small 3
	
Mistral
	
Open
	
32k
	

Model

API Providers



Mistral Small (Sep '24)
	
Mistral
	
Open
	
33k
	

Model

API Providers



Mixtral 8x22B Instruct
	
Mistral
	
Open
	
65k
	

Model

API Providers



Mistral Small (Feb '24)
	
Mistral
	
Proprietary
	
33k
	

Model

API Providers



Mistral Large (Feb '24)
	
Mistral
	
Proprietary
	
33k
	

Model

API Providers



Pixtral 12B (2409)
	
Mistral
	
Open
	
128k
	

Model

API Providers



Mistral NeMo
	
Mistral
	
Open
	
128k
	

Model

API Providers



Mixtral 8x7B Instruct
	
Mistral
	
Open
	
33k
	

Model

API Providers



Codestral-Mamba
	
Mistral
	
Open
	
256k
	

Model

API Providers



Mistral 7B Instruct
	
Mistral
	
Open
	
8k
	

Model

API Providers



Mistral Small 3.1
	
Mistral
	
Open
	
128k
	

Model

API Providers



Codestral (May '24)
	
Mistral
	
Open
	
33k
	

Model

API Providers



Devstral Small (May '25)
	
Mistral
	
Open
	
256k
	

Model

API Providers



Mistral Saba
	
Mistral
	
Proprietary
	
32k
	

Model

API Providers



Mistral Medium
	
Mistral
	
Proprietary
	
33k
	

Model

API Providers



		

DeepSeek V3.1 (Non-reasoning)
	
DeepSeek
	
Open
	
128k
	

Model

API Providers



DeepSeek V3.1 (Reasoning)
	
DeepSeek
	
Open
	
128k
	

Model

API Providers



DeepSeek R1 0528 (May '25)
	
DeepSeek
	
Open
	
128k
	

Model

API Providers



DeepSeek R1 0528 Qwen3 8B
	
DeepSeek
	
Open
	
33k
	

Model

API Providers



DeepSeek R1 Distill Llama 70B
	
DeepSeek
	
Open
	
128k
	

Model

API Providers



DeepSeek R1 Distill Qwen 32B
	
DeepSeek
	
Open
	
128k
	

Model

API Providers



DeepSeek V3 (Dec '24)
	
DeepSeek
	
Open
	
128k
	

Model

API Providers



DeepSeek R1 Distill Qwen 14B
	
DeepSeek
	
Open
	
128k
	

Model

API Providers



DeepSeek-V2.5 (Dec '24)
	
DeepSeek
	
Open
	
128k
	

Model

API Providers



DeepSeek-Coder-V2
	
DeepSeek
	
Open
	
128k
	

Model

API Providers



DeepSeek R1 Distill Llama 8B
	
DeepSeek
	
Open
	
128k
	

Model

API Providers



DeepSeek LLM 67B Chat (V1)
	
DeepSeek
	
Open
	
4k
	

Model

API Providers



DeepSeek R1 Distill Qwen 1.5B
	
DeepSeek
	
Open
	
128k
	

Model

API Providers



DeepSeek V3 0324
	
DeepSeek
	
Open
	
128k
	

Model

API Providers



DeepSeek R1 (Jan '25)
	
DeepSeek
	
Open
	
128k
	

Model

API Providers



DeepSeek-V2.5
	
DeepSeek
	
Open
	
128k
	

Model

API Providers



DeepSeek Coder V2 Lite Instruct
	
DeepSeek
	
Open
	
128k
	

Model

API Providers



DeepSeek-V2-Chat
	
DeepSeek
	
Open
	
128k
	

Model

API Providers



		

R1 1776
	
Perplexity
	
Open
	
128k
	

Model

API Providers



Sonar
	
Perplexity
	
Proprietary
	
127k
	

Model

API Providers



Sonar Reasoning
	
Perplexity
	
Proprietary
	
127k
	

Model

API Providers



Sonar Reasoning Pro
	
Perplexity
	
Proprietary
	
127k
	

Model

API Providers



Sonar Pro
	
Perplexity
	
Proprietary
	
200k
	

Model

API Providers



		

Nova Premier
	
Amazon
	
Proprietary
	
1m
	

Model

API Providers



Nova Pro
	
Amazon
	
Proprietary
	
300k
	

Model

API Providers



Nova Lite
	
Amazon
	
Proprietary
	
300k
	

Model

API Providers



Nova Micro
	
Amazon
	
Proprietary
	
130k
	

Model

API Providers



		

Phi-4
	
Microsoft Azure
	
Open
	
16k
	

Model

API Providers



Phi-4 Multimodal Instruct
	
Microsoft Azure
	
Open
	
128k
	

Model

API Providers



Phi-3 Medium Instruct 14B
	
Microsoft Azure
	
Open
	
128k
	

Model

API Providers



Phi-4 Mini Instruct
	
Microsoft Azure
	
Open
	
128k
	

Model

API Providers



Phi-3 Mini Instruct 3.8B
	
Microsoft Azure
	
Open
	
4k
	

Model

API Providers



		

LFM2 1.2B
	
Liquid AI
	
Open
	
33k
	

Model

API Providers



LFM 40B
	
Liquid AI
	
Proprietary
	
32k
	

Model

API Providers



		

Solar Pro 2 (Reasoning)
	
Upstage
	
Proprietary
	
66k
	

Model

API Providers



Solar Pro 2
	
Upstage
	
Proprietary
	
66k
	

Model

API Providers



Solar Mini
	
Upstage
	
Open
	
4k
	

Model

API Providers



Solar Pro 2 (Preview) (Reasoning)
	
Upstage
	
Proprietary
	
64k
	

Model

API Providers



Solar Pro 2 (Preview)
	
Upstage
	
Proprietary
	
64k
	

Model

API Providers



		

MiniMax-Text-01
	
MiniMax
	
Open
	
4m
	

Model

API Providers



MiniMax M1 80k
	
MiniMax
	
Open
	
1m
	

Model

API Providers



MiniMax M1 40k
	
MiniMax
	
Open
	
1m
	

Model

API Providers



		

Llama 3.1 Nemotron Instruct 70B
	
NVIDIA
	
Open
	
128k
	

Model

API Providers



Llama 3.1 Nemotron Ultra 253B v1 (Reasoning)
	
NVIDIA
	
Open
	
128k
	

Model

API Providers



Llama 3.3 Nemotron Super 49B v1
	
NVIDIA
	
Open
	
128k
	

Model

API Providers



NVIDIA Nemotron Nano 9B V2 (Reasoning)
	
NVIDIA
	
Open
	
131k
	

Model

API Providers



Llama 3.1 Nemotron Nano 4B v1.1 (Reasoning)
	
NVIDIA
	
Open
	
128k
	

Model

API Providers



Llama 3.3 Nemotron Super 49B v1 (Reasoning)
	
NVIDIA
	
Open
	
128k
	

Model

API Providers



NVIDIA Nemotron Nano 9B V2
	
NVIDIA
	
Open
	
131k
	

Model

API Providers



Llama Nemotron Super 49B v1.5 (Reasoning)
	
NVIDIA
	
Open
	
128k
	

Model

API Providers



Llama Nemotron Super 49B v1.5
	
NVIDIA
	
Open
	
128k
	

Model

API Providers



		

Kimi K2
	
Moonshot AI
	
Open
	
128k
	

Model

API Providers



Kimi K2 0905
	
Moonshot AI
	
Open
	
256k
	

Model

API Providers



		

Granite 3.3 Instruct 8B
	
IBM
	
Open
	
128k
	

Model

API Providers



		

Reka Flash 3
	
Reka AI
	
Open
	
128k
	

Model

API Providers



Reka Flash (Sep '24)
	
Reka AI
	
Proprietary
	
128k
	

Model

API Providers



Reka Core
	
Reka AI
	
Proprietary
	
128k
	

Model

API Providers



Reka Flash (Feb '24)
	
Reka AI
	
Proprietary
	
128k
	

Model

API Providers



Reka Edge
	
Reka AI
	
Proprietary
	
128k
	

Model

API Providers



		

DeepHermes 3 - Llama-3.1 8B Preview
	
Nous Research
	
Open
	
128k
	

Model

API Providers



Hermes 4 - Llama-3.1 405B (Reasoning)
	
Nous Research
	
Open
	
128k
	

Model

API Providers



Hermes 4 - Llama-3.1 70B (Reasoning)
	
Nous Research
	
Open
	
128k
	

Model

API Providers



DeepHermes 3 - Mistral 24B Preview
	
Nous Research
	
Open
	
32k
	

Model

API Providers



Hermes 4 - Llama-3.1 405B
	
Nous Research
	
Open
	
128k
	

Model

API Providers



Hermes 4 - Llama-3.1 70B
	
Nous Research
	
Open
	
128k
	

Model

API Providers



Hermes 3 - Llama-3.1 70B
	
Nous Research
	
Open
	
128k
	

Model

API Providers



		

EXAONE 4.0 32B
	
LG AI Research
	
Open
	
131k
	

Model

API Providers



EXAONE 4.0 32B (Reasoning)
	
LG AI Research
	
Open
	
131k
	

Model

API Providers



Exaone 4.0 1.2B
	
LG AI Research
	
Open
	
64k
	

Model

API Providers



Exaone 4.0 1.2B (Reasoning)
	
LG AI Research
	
Open
	
64k
	

Model

API Providers



		

GLM-4.5
	
Z AI
	
Open
	
128k
	

Model

API Providers



GLM-4.5V
	
Z AI
	
Open
	
64k
	

Model

API Providers



GLM-4.5-Air
	
Z AI
	
Open
	
128k
	

Model

API Providers



GLM-4.5V (Reasoning)
	
Z AI
	
Open
	
64k
	

Model

API Providers



		

Aya Expanse 32B
	
Cohere
	
Open
	
128k
	

Model

API Providers



Aya Expanse 8B
	
Cohere
	
Open
	
8k
	

Model

API Providers



Command A
	
Cohere
	
Open
	
256k
	

Model

API Providers



Command-R+ (Aug '24)
	
Cohere
	
Open
	
128k
	

Model

API Providers



Command-R+ (Apr '24)
	
Cohere
	
Open
	
128k
	

Model

API Providers



Command-R (Aug '24)
	
Cohere
	
Open
	
128k
	

Model

API Providers



Command-R (Mar '24)
	
Cohere
	
Open
	
128k
	

Model

API Providers



		

Jamba 1.7 Mini
	
AI21 Labs
	
Open
	
258k
	

Model

API Providers



Jamba 1.7 Large
	
AI21 Labs
	
Open
	
256k
	

Model

API Providers



Jamba Instruct
	
AI21 Labs
	
Proprietary
	
256k
	

Model

API Providers



Jamba 1.5 Large
	
AI21 Labs
	
Open
	
256k
	

Model

API Providers



Jamba 1.5 Mini
	
AI21 Labs
	
Open
	
256k
	

Model

API Providers



Jamba 1.6 Mini
	
AI21 Labs
	
Open
	
256k
	

Model

API Providers



Jamba 1.6 Large
	
AI21 Labs
	
Open
	
256k
	

Model

API Providers



		

Qwen3 Coder 480B A35B
	
Alibaba
	
Open
	
262k
	

Model

API Providers



Qwen3 Next 80B A3B
	
Alibaba
	
Open
	
262k
	

Model

API Providers



QwQ 32B
	
Alibaba
	
Open
	
131k
	

Model

API Providers



Qwen3 235B A22B 2507 (Non-reasoning)
	
Alibaba
	
Open
	
256k
	

Model

API Providers



Qwen3 Next 80B A3B (Reasoning)
	
Alibaba
	
Open
	
262k
	

Model

API Providers



Qwen3 235B A22B 2507 (Reasoning)
	
Alibaba
	
Open
	
256k
	

Model

API Providers



Qwen3 Coder 30B A3B
	
Alibaba
	
Open
	
262k
	

Model

API Providers



Qwen3 30B A3B 2507 (Reasoning)
	
Alibaba
	
Open
	
262k
	

Model

API Providers



Qwen3 30B A3B 2507 (Non-reasoning)
	
Alibaba
	
Open
	
262k
	

Model

API Providers



Qwen3 4B 2507 (Reasoning)
	
Alibaba
	
Open
	
262k
	

Model

API Providers



Qwen3 Max (Preview)
	
Alibaba
	
Proprietary
	
262k
	

Model

API Providers



Qwen Chat 14B
	
Alibaba
	
Open
	
8k
	

Model

API Providers



Qwen2.5 Max
	
Alibaba
	
Proprietary
	
32k
	

Model

API Providers



Qwen2.5 Instruct 72B
	
Alibaba
	
Open
	
131k
	

Model

API Providers



Qwen2.5 Coder Instruct 32B
	
Alibaba
	
Open
	
131k
	

Model

API Providers



Qwen2.5 Turbo
	
Alibaba
	
Proprietary
	
1m
	

Model

API Providers



Qwen2 Instruct 72B
	
Alibaba
	
Open
	
131k
	

Model

API Providers



Qwen2.5 Coder Instruct 7B
	
Alibaba
	
Open
	
131k
	

Model

API Providers



Qwen3 235B A22B
	
Alibaba
	
Open
	
33k
	

Model

API Providers



Qwen3 4B
	
Alibaba
	
Open
	
32k
	

Model

API Providers



Qwen3 235B A22B (Reasoning)
	
Alibaba
	
Open
	
33k
	

Model

API Providers



Qwen3 8B (Reasoning)
	
Alibaba
	
Open
	
131k
	

Model

API Providers



Qwen2.5 Instruct 32B
	
Alibaba
	
Open
	
128k
	

Model

API Providers



Qwen3 1.7B (Reasoning)
	
Alibaba
	
Open
	
32k
	

Model

API Providers



Qwen3 32B (Reasoning)
	
Alibaba
	
Open
	
33k
	

Model

API Providers



Qwen3 32B
	
Alibaba
	
Open
	
33k
	

Model

API Providers



Qwen3 14B (Reasoning)
	
Alibaba
	
Open
	
33k
	

Model

API Providers



Qwen3 30B A3B (Reasoning)
	
Alibaba
	
Open
	
33k
	

Model

API Providers



Qwen3 4B (Reasoning)
	
Alibaba
	
Open
	
32k
	

Model

API Providers



Qwen3 1.7B
	
Alibaba
	
Open
	
32k
	

Model

API Providers



Qwen1.5 Chat 110B
	
Alibaba
	
Open
	
32k
	

Model

API Providers



QwQ 32B-Preview
	
Alibaba
	
Open
	
33k
	

Model

API Providers



Qwen3 8B
	
Alibaba
	
Open
	
33k
	

Model

API Providers



Qwen3 0.6B (Reasoning)
	
Alibaba
	
Open
	
32k
	

Model

API Providers



Qwen3 0.6B
	
Alibaba
	
Open
	
32k
	

Model

API Providers



Qwen3 14B
	
Alibaba
	
Open
	
33k
	

Model

API Providers



Qwen3 30B A3B
	
Alibaba
	
Open
	
33k
	

Model

API Providers



Qwen Chat 72B
	
Alibaba
	
Open
	
34k
	

Model

API Providers



		

OpenChat 3.5 (1210)
	
OpenChat
	
Open
	
8k
	

Model

API Providers



		

DBRX Instruct
	
Databricks
	
Open
	
33k
	

Model

API Providers



		

Llama 3.1 Tulu3 405B
	
Allen Institute for AI
	
Open
	
128k
	

Model

API Providers



		

Arctic Instruct
	
Snowflake
	
Open
	
4k
	

Model

API Providers



		

Yi-Large
	
01.AI
	
Proprietary
	
32k
	

Model

API Providers

Footer
Key Links
Compare Language Models
Language Models Leaderboard
Language Model API Leaderboard
Image Arena
Video Arena
Speech Arena
Artificial Analysis
FAQ
Contact & Data access
Terms of Use
Privacy Policy
hello@artificialanalysis.ai
Subscribe to our newsletter
Email address
Subscribe
Twitter
LinkedIn